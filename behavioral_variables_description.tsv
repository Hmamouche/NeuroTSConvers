Modality	Features	Description	Remarques
Speech	SpeechActivity	Detecting speech activity from audio file.	
	IUP	The speech activity computed from transcriptions.	
	overlap	Compute overlap durations of speech activity from transcriptions between both interlocutors.	
	filled_breaks	The ratio of filled breaks items  in each time step.	"'[u""euh"",u""heu"",u""hum"",u""mh""]"
	feed_back	The ratio of feedbacks in each time step.	"'[u""mh"",u""ouais"",u""oui"",u''non'',u''ah'',u""mouais""]+ OK_FORMS + VOILA_FORMS + DACCORD_FORMS + LAUGHTER_FORMS'"
	discourse_markers	The ratio of discourse marskers durations in each tim step.	"'[u""alors"",u""mais"",u""donc"",u''et'',u''puis'',u''enfin'',u''parceque'',u''parcequ'',u''ensuite'']'"
	Laughers	The ratio of laughers durations in each tim step.	'[u''@'',u''@ @'',u''@@'']'
	particles_items	The ratio of particle  markers in each tim step.	"'[u""quoi"",u""hein"",u""bon"",u''mais'',u''ben'',u''beh'',u''enfin'',u''vois'',u''putain'',u''bref'']'"
	reaction_time	The waiting or reaction time after responding. It is positive if the interlocutor wait some time then respond, or negative if there is overlap.	
	Polarity	This metric is calculated for each IPU. Then, we consider the obtained value (in the range [0,1]) at the time point close to the center of the IPU.	https://stackabuse.com/python-for-nlp-introduction-to-the-pattern-library/ 
	Subjectivity	This metric is calculated for each IPU. Then, we consider the obtained value (in the range [0,1]) at the time point close to the center of the IPU.	https://stackabuse.com/python-for-nlp-introduction-to-the-pattern-library/
	Lexical_richness_1	This metric is calculated for each IPU as follows: (nbr of different tokens) / (total nbr of tokens)	
	Lexical_richness_2	Similarily to lexical_richness_1: (nbr of adjectifs + nbr of adverbes) / (total nbr of tokens)	
Video	gaze_angle_x	Gaze angle x coordinate	
	gaze_angle_y	Gaze angle y coordinate	
	Head_translation_energy	Kinetic energy of head translation	
	Head_rotation_energy	Kinetic energy of head rotation	
	mouth_AU	Sum of action units associated to mouth movements (AU10_r, AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU23_r, AU25_r, AU26_r)	
	eyes_AU	Sum of action units associated to eyes movements (AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU07_r, AU09_r)	
	Total_AU	Sum of all action units	
	Emotions	Emotions from videos image per image using a pre-trained model ('Happiness', 'Sadness','Surprise', 'Fear', 'Anger', 'Disgust').	https://github.com/oarriaga/face_classification
	dlib-smiles	detecting smiles using dlib pre-trained model (binary variable, 1 if there is smile else 0).	
	Smiles	detecting smiles using facial action units	https://github.com/srauzy/HMAD  
Eyetracking	saccades	Binary variable, 1 if there is saccades, else 0.	
	Vx, Vy	Speed of the gaze coordinates.	
	Face	Binary variable, 1 if the subject is looking at the face of the agent, else 0.	
	Eye	Binary variable, 1 if the subject is looking at one eye of the agent, else 0.	
	Mouth	Binary variable, 1 if the subject is looking at the mouth of the agent, else 0.	
